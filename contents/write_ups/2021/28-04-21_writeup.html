
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Data Ethics Club discussion: We created poverty. Algorithms won’t make that go away &#8212; Data Ethics Club v0.1.0 documentation</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Reading list" href="../../reading-list.html" />
    <link rel="prev" title="Data Ethics Club discusses: UK Statistics Authority: Identifying gaps, opportunities and priorities in the applied data ethics guidance landscape" href="14-04-21_writeup.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../../../index.html">
<p class="title">Data Ethics Club</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../write-ups.html">
  Write-ups
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../reading-list.html">
  Reading list
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../administration.html">
  Organising
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../get-involved.html">
  Join us
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../meetings/meetings.html">
  Meeting Dates
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../contact.html">
  Contact us
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/very-good-science/data-ethics-club" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/hashtag/DataEthicsClub" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this site..." aria-label="Search this site..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="17-03-21_writeup.html">
   Data Ethics Club discusses “#bropenscience is broken science”
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="31-03-21_writeup.html">
   Data Ethics Club discusses Dataism Is Our New God
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14-04-21_writeup.html">
   Data Ethics Club discusses: UK Statistics Authority: Identifying gaps, opportunities and priorities in the applied data ethics guidance landscape
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Data Ethics Club discussion: We created poverty. Algorithms won’t make that go away
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#intro">
   Intro
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-deserving-of-help-are-we-is-this-a-reasonable-question-or-is-it-just-uncomfortable">
   How deserving of help are we? Is this a reasonable question (or is it just uncomfortable)?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#in-projects-that-involve-direct-impacts-on-people-s-lives-does-everything-need-to-be-automated-and-optimised">
   In projects that involve direct impacts on people’s lives, does everything need to be automated and optimised?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#in-what-ways-can-data-scientists-positively-contribute-fair-algorithmic-decision-making">
   In what ways can data scientists positively contribute fair algorithmic decision-making?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#closing-thoughts">
   Closing thoughts
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#voting">
   Voting
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#contributors">
   Contributors:
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="data-ethics-club-discussion-we-created-poverty-algorithms-won-t-make-that-go-away">
<h1>Data Ethics Club discussion: <a class="reference external" href="https://www.theguardian.com/commentisfree/2018/may/13/we-created-poverty-algorithms-wont-make-that-go-away">We created poverty. Algorithms won’t make that go away</a><a class="headerlink" href="#data-ethics-club-discussion-we-created-poverty-algorithms-won-t-make-that-go-away" title="Permalink to this headline">¶</a></h1>
<div class="admonition-what-is-this admonition">
<p class="admonition-title">What is this?</p>
<p>This is summary of Wednesday 28th April’s Data Ethics Club discussion, where we spoke and wrote about the piece <a class="reference external" href="https://www.theguardian.com/commentisfree/2018/may/13/we-created-poverty-algorithms-wont-make-that-go-away">“We created poverty. Algorithms won’t make that go away” </a>, which is an article written by Virginia Eubanks, author of “Automating Inequality”. As one of the attendees pointed out, the article was in some senses a summary of some of the ideas from the book, which comes highly recommended!</p>
<p>The summary was written by Huw Day, who tried to synthesise everyone’s contributions to this document and the discussion. “We” = “someone at Data Ethics Club”.</p>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>Algorithms are being deployed to decide who can access scarce public resources.</p>
<p>We are constantly making personal decisions about resource allocation - do you deserve takeout tonight?
A day off next week?
A holiday this year?
In doing so, we consider available resources (both our own and those of others), expected payoff and how deserving we are.
No algorithm required.</p>
<p>Are algorithms just shields for people to hide behind?
When used in that way, is AI decision-making fundamentally different to using people or government departments as the scapegoat for failures instead?</p>
<p>You can’t fix the problem of not enough resources with distributing those resources more “efficiently”, but does that mean you shouldn’t try?</p>
</div>
<div class="section" id="intro">
<h2>Intro<a class="headerlink" href="#intro" title="Permalink to this headline">¶</a></h2>
<p>In <a class="reference external" href="https://www.theguardian.com/commentisfree/2018/may/13/we-created-poverty-algorithms-wont-make-that-go-away">this piece from The Guardian</a>, Virgina Eubanks shares her experiences of travelling the United States to study and write about the impact of hi-tech tools on public service programs.
She notes: “We are increasingly turning to digital tools to rank and rate which struggling families most deserve support.”</p>
<p>Since the ethical dilemmas are plentiful when attempting to share out insufficient resources among many needing and deserving causes, someone has to make the difficult decision as to what (and perhaps more crucially, who) constitutes a more or less “deserving” cause.
As Eubanks puts it, this task is of ranking deservingness is being outsourced to algorithms because “humans know better”.
Deceptively though, this means that whoever designs the algorithms gets to decide what the metrics are for “deservingness” - and surely they should know better?</p>
</div>
<div class="section" id="how-deserving-of-help-are-we-is-this-a-reasonable-question-or-is-it-just-uncomfortable">
<h2>How deserving of help are we? Is this a reasonable question (or is it just uncomfortable)?<a class="headerlink" href="#how-deserving-of-help-are-we-is-this-a-reasonable-question-or-is-it-just-uncomfortable" title="Permalink to this headline">¶</a></h2>
<p>We can all understand the potential benefit of efficiency in decision-making.
However, it’s one thing to optimise the distribution of sufficient resources, and another to allocate insufficient resources to the most “deserving” cause.</p>
<p>Any form of optimising requires choosing parameters to optimise and this evaluation will inevitably be done from an outsider’s perspective.
If we put these optimisation decisions in the hands of technology, we need to ask if they are effective in reducing harm.
If they are ineffective, then it adds insult to injury because in addition to making the situation worse, you’re paying for it.</p>
<p>Meritocracy is often a story the successful tell about themselves, forgetting their starting advantages and luck along the way.
In contrast, blame is placed on the unsuccessful for perceived “failure”.
This means “deservingness” may be exactly the wrong lens to look through.</p>
</div>
<div class="section" id="in-projects-that-involve-direct-impacts-on-people-s-lives-does-everything-need-to-be-automated-and-optimised">
<h2>In projects that involve direct impacts on people’s lives, does everything need to be automated and optimised?<a class="headerlink" href="#in-projects-that-involve-direct-impacts-on-people-s-lives-does-everything-need-to-be-automated-and-optimised" title="Permalink to this headline">¶</a></h2>
<p>When resources are inadequate, inefficient distribution of what resources there are is unlikely to help persuade politicians or other decision makers to increase the resources.
This decreases the opportunity for creative solutions that are not accounted for in the parameters.
Applying an algorithmic solution to a resource management problem has the external appearance of a “fix” whilst hiding the fact that the best “fix” is to have more resources.</p>
<p>If you have three people and two chairs, you can run a complex algorithm to decide who is most deserving of a seat at the table based on medical historical, gym memberships and perhaps how altrusistic each person is. Or you could just get a third chair?</p>
<p>However, these impossible decisions about resource allocation are the day-to-day reality of many public sector services and local government.<br />
As a result they are continually being pitched software solutions to “smartify” certain processes by tech companies coming from the outside and not understanding how local government works.
These can be very expensive and well-marketed but unless their resource saving utility over the original system exceeds the costs of implementation, you are inevitably making a loss in the short term and reducing your already inadequate resources.</p>
<p>Algorithmic decision making is not all bad news. Consider the issue of food waste; automation and optimisation could do a great deal of good there.
But do these optimisations give us a free ride to avoid looking at other deeper issues e.g. dumpster locking/participation?
Algorithms can’t fix everything, but sometimes it is possible that they can ensure the most vulnerable get more help they would get from human decisions.
If there isn’t a third chair and an algorithm can make a fairer choice than a human, perhaps algorithms have their place in decision-making after all.
Crucially, it is often unclear which situation we are in.</p>
<p>Even if we were to know that the resources are being more efficiently allocated on average, we also want to ensure that they are not benefiting certain groups over others.</p>
<p>There is also a distinction to be made between “automated” and “digital”.
Automating a task to free up resources can often be more cost effective than getting a person to do it, but potentially at the cost of taking a vital input of human empathy out of the decision making.
Digitising a process is simply moving from information into a form that can be read, stored and processed by a computer.
Digitising a task both increases the scope of automation but also potentially allows a human decision maker to more easily consider all the variables at play in their decisions.</p>
<p>In general, we need more empathy in our decision making and should not forget to be human when that’s the better answer to the challenges we face.</p>
</div>
<div class="section" id="in-what-ways-can-data-scientists-positively-contribute-fair-algorithmic-decision-making">
<h2>In what ways can data scientists positively contribute fair algorithmic decision-making?<a class="headerlink" href="#in-what-ways-can-data-scientists-positively-contribute-fair-algorithmic-decision-making" title="Permalink to this headline">¶</a></h2>
<p>Often data scientists choose to work on areas like poverty because they want to use their technical skills to help.
However, doing that alone could cause more harm than good.</p>
<p>It’s not possible to “outsource our ethical choices to machines”, because machines can’t make ethical choices, the ethical choices are made by the humans in the way they implement system.
This means we must take responsibility for these choices as we make them.
Similarly, we should do what we can to ensure anyone who uses our code understands that they take on the responsibility for how it is deployed.</p>
<p>There’s a sense in the article that technology becomes a solution to cowardice: “The goal of automated decision-making, they told me is… also to help make the heartbreaking choices of whom among the most exploited and marginalized people in the United States will get help.”
Decision makers are avoiding hard decisions in considering issues like job applications, austerity measures etc.
Rather than dealing with the lack of resources head on, they circumvent dealing with the issue head on in a manner which will actually propogate the issue.</p>
<p>Data scientists can contribute by advocating for “non-technical” forms of knowledge (e.g. from the user-centred research).
Communicating the limits of their work can also help to ensure that data science is used to assist human case workers rather than replace them and/or to simply allocate more resources to the situation, where appropriate.</p>
</div>
<div class="section" id="closing-thoughts">
<h2>Closing thoughts<a class="headerlink" href="#closing-thoughts" title="Permalink to this headline">¶</a></h2>
<p>We don’t want to make difficult decisions, so it’s easier to pass that decision to an algorithm who can take the blame, but you can’t apply software fixes for hardware problems.
The feeling is that we are generally pessimitic about what you can do to do good with algorithms, although there is potential scope for good.</p>
<p>Making arguments against optimisation wasn’t the point of the article or our discussion - data scientists decide what to optimise for, and in what context.
Is it so bad to optimise things that will help people (such as who is most likely to surive a kidney transplant)?
Algorithms can add value in certain settings and data scientists could help optimise certain outcomes.</p>
<p>But it it can be difficult decide how “deserving” people are of help, and even to decide if “deservingness” is the correct metric to try to use.
If you automate a problem, you often won’t get creative solutions so whilst optimisation is useful, you have to marry it with strong policy proposals.</p>
<p>In order to help, we constantly need to be ethically reviewing our approaches - this can be difficult if you’re the sole data scientist in your context.
Constantly discussing these ideas with peers and colleagues is a great way to get this process of self evaluation going and our best bet to apply algorithms more ethically.
This is the best way to avoid making poorer/marginalised people the “guinea pigs” for the algorithms of the future.</p>
</div>
<div class="section" id="voting">
<h2>Voting<a class="headerlink" href="#voting" title="Permalink to this headline">¶</a></h2>
<p>Our vote for the next meeting was to discuss:</p>
<p><a class="reference external" href="https://slideslive.com/38923500/critical-perspectives-on-computer-vision">Critical Perspectives on Computer Vision</a> - a ~20 minute video about image recognition/categorisation by Emily Denton, a Senior Research Scientist on Google’s Ethical AI team</p>
<p>and save these two for another time:</p>
<p><a class="reference external" href="https://arxiv.org/pdf/1607.06520.pdf">Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings</a> - paper about how to make word embeddings in language models less biased</p>
<p><a class="reference external" href="https://psyarxiv.com/2mdxh/">A manifesto for big team science</a> - preprint about barriers to doing science as a team (based in psychology)</p>
<p>Our members also said:</p>
<ul class="simple">
<li><p>100% (12 people) that the content this week sparked interesting discussion.</p></li>
<li><p>92% (11 people) said that they’d recommend that others read the content.</p></li>
</ul>
</div>
<div class="section" id="contributors">
<h2>Contributors:<a class="headerlink" href="#contributors" title="Permalink to this headline">¶</a></h2>
<div class="tip admonition">
<p class="admonition-title">Who contributed?</p>
<p>This is the list of contributors who were comfortable sharing their names publicly.</p>
</div>
<ul class="simple">
<li><p>Natalie Thurlby, Data Scientist, University of Bristol, <a class="reference external" href="https://github.com/NatalieThurlby/">NatalieThurlby</a>, <a class="reference external" href="https://twitter.com/StatalieT">&#64;StatalieT</a>, :sun_with_face:</p></li>
<li><p>Nina Di Cara, PhD Student, University of Bristol, <a class="reference external" href="https://github.com/ninadicara/">ninadicara</a>, <a class="reference external" href="https://twitter.com/ninadicara">&#64;ninadicara</a>, :writing_hand:</p></li>
<li><p>Huw Day, Maths PhDoer, Bristol, <a class="reference external" href="https://twitter.com/disco_huw">&#64;disco_huw</a></p></li>
<li><p>Robin Dasler, data product manager on hiatus, <a class="reference external" href="https://github.com/daslerr">github:daslerr</a></p></li>
<li><p>Paul Lee, investor, &#64;pclee27 www.senseoffairness.blog</p></li>
<li><p>Kamilla Wells, Citizen Developer, Australia <a class="reference external" href="https://www.linkedin.com/in/kamilla-wells/">Kamilla Wells</a></p></li>
<li><p>Miranda Mowbray, honorary lecturer, University of Bristol, mirandamowbray on LinkedIn</p></li>
</ul>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="14-04-21_writeup.html" title="previous page">Data Ethics Club discusses: UK Statistics Authority: Identifying gaps, opportunities and priorities in the applied data ethics guidance landscape</a>
    <a class='right-next' id="next-link" href="../../reading-list.html" title="next page">Reading list</a>

              </div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Natalie Thurlby and Nina Di Cara.<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.4.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>